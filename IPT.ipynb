{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IPT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKjouvtkE4ttJ9qyPmlVSz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohit1349/Pretrained-IPT/blob/main/IPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0IHbRLsHFciA"
      },
      "outputs": [],
      "source": [
        "#https://github.com/huawei-noah/Pretrained-IPT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/huawei-noah/Pretrained-IPT/archive/refs/heads/main.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fko4ZxhsEO0M",
        "outputId": "98b83fdc-2fde-40e5-c345-ee6bb58941cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-25 06:35:46--  https://github.com/huawei-noah/Pretrained-IPT/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/huawei-noah/Pretrained-IPT/zip/refs/heads/main [following]\n",
            "--2022-01-25 06:35:46--  https://codeload.github.com/huawei-noah/Pretrained-IPT/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [  <=>               ]   8.60M  22.9MB/s    in 0.4s    \n",
            "\n",
            "2022-01-25 06:35:47 (22.9 MB/s) - ‘main.zip’ saved [9018314]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6jUDlUCIeJe",
        "outputId": "fc1b4eae-0340-4f65-c90e-4316d4248081"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip main.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWV0MzsbIgNX",
        "outputId": "a1815a8c-2074-44e5-8015-9e7d40076bdb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  main.zip\n",
            "fd0df98c42d62b13ec0c61c70a20f1e75a3f5ecd\n",
            "   creating: Pretrained-IPT-main/\n",
            "  inflating: Pretrained-IPT-main/License.txt  \n",
            "  inflating: Pretrained-IPT-main/THIRD PARTY OPEN SOURCE SOFTWARE NOTICE.txt  \n",
            "   creating: Pretrained-IPT-main/data/\n",
            "  inflating: Pretrained-IPT-main/data/__init__.py  \n",
            "  inflating: Pretrained-IPT-main/data/benchmark.py  \n",
            "  inflating: Pretrained-IPT-main/data/common.py  \n",
            "  inflating: Pretrained-IPT-main/data/demo.py  \n",
            "  inflating: Pretrained-IPT-main/data/div2k.py  \n",
            "  inflating: Pretrained-IPT-main/data/div2kjpeg.py  \n",
            "  inflating: Pretrained-IPT-main/data/sr291.py  \n",
            "  inflating: Pretrained-IPT-main/data/srdata.py  \n",
            "  inflating: Pretrained-IPT-main/dataloader.py  \n",
            "   creating: Pretrained-IPT-main/images/\n",
            "  inflating: Pretrained-IPT-main/images/dn_result.PNG  \n",
            "  inflating: Pretrained-IPT-main/images/dr_result.png  \n",
            "  inflating: Pretrained-IPT-main/images/intro.png  \n",
            "  inflating: Pretrained-IPT-main/images/sr_result.PNG  \n",
            "   creating: Pretrained-IPT-main/loss/\n",
            "  inflating: Pretrained-IPT-main/loss/__init__.py  \n",
            "  inflating: Pretrained-IPT-main/main.py  \n",
            "   creating: Pretrained-IPT-main/model/\n",
            "  inflating: Pretrained-IPT-main/model/__init__.py  \n",
            "  inflating: Pretrained-IPT-main/model/common.py  \n",
            "  inflating: Pretrained-IPT-main/model/ipt.py  \n",
            "  inflating: Pretrained-IPT-main/option.py  \n",
            "  inflating: Pretrained-IPT-main/readme.md  \n",
            "  inflating: Pretrained-IPT-main/trainer.py  \n",
            "  inflating: Pretrained-IPT-main/utility.py  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYz_Hkj6IjYW",
        "outputId": "88cdb5b5-8a02-4a23-b5a1-46790746eda5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main.zip  Pretrained-IPT-main  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70fz5qspIlfm",
        "outputId": "475ef6a8-7a12-4358-b371-5f2e4e009968"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t      mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Pretrained-IPT-main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JO_QmacKAVI",
        "outputId": "73fb2f01-95de-49f4-f0c7-a0cded584ca5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " data\t\t loss\t     readme.md\n",
            " dataloader.py\t main.py    'THIRD PARTY OPEN SOURCE SOFTWARE NOTICE.txt'\n",
            " images\t\t model\t     trainer.py\n",
            " License.txt\t option.py   utility.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thstkdgus35/EDSR-PyTorch"
      ],
      "metadata": {
        "id": "g7GJkxhbQAp7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88b7aed-eb48-4177-f6fb-f0a5f86c5389"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EDSR-PyTorch'...\n",
            "remote: Enumerating objects: 797, done.\u001b[K\n",
            "remote: Total 797 (delta 0), reused 0 (delta 0), pack-reused 797\u001b[K\n",
            "Receiving objects: 100% (797/797), 63.09 MiB | 31.54 MiB/s, done.\n",
            "Resolving deltas: 100% (511/511), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK3AkGgh8wiy",
        "outputId": "8dac8c24-1a39-43f0-ffd7-40dc0e1358ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EDSR-PyTorch  main.zip\tPretrained-IPT-main  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l EDSR-PyTorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EcydktG8zOx",
        "outputId": "1a503c10-7f19-42d3-8026-f6a37b3de98a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 32\n",
            "drwxr-xr-x 2 root root  4096 Jan 25 06:36 experiment\n",
            "drwxr-xr-x 2 root root  4096 Jan 25 06:36 figs\n",
            "-rw-r--r-- 1 root root  1069 Jan 25 06:36 LICENSE\n",
            "-rwxr-xr-x 1 root root 10940 Jan 25 06:36 README.md\n",
            "drwxr-xr-x 5 root root  4096 Jan 25 06:36 src\n",
            "drwxr-xr-x 2 root root  4096 Jan 25 06:36 test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "\n",
        "import threading\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.multiprocessing as multiprocessing\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "from torch.utils.data import RandomSampler\n",
        "from torch.utils.data import BatchSampler\n",
        "from torch.utils.data import _utils\n",
        "from torch.utils.data.dataloader import _DataLoaderIter\n",
        "\n",
        "from torch.utils.data._utils import collate\n",
        "from torch.utils.data._utils import signal_handling\n",
        "from torch.utils.data._utils import MP_STATUS_CHECK_INTERVAL\n",
        "from torch.utils.data._utils import ExceptionWrapper\n",
        "from torch.utils.data._utils import IS_WINDOWS\n",
        "from torch.utils.data._utils.worker import ManagerWatchdog\n",
        "\n",
        "from torch._six import queue\n",
        "\n",
        "def _ms_loop(dataset, index_queue, data_queue, done_event, collate_fn, scale, seed, init_fn, worker_id):\n",
        "    try:\n",
        "        collate._use_shared_memory = True\n",
        "        signal_handling._set_worker_signal_handlers()\n",
        "\n",
        "        torch.set_num_threads(1)\n",
        "        random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        data_queue.cancel_join_thread()\n",
        "\n",
        "        if init_fn is not None:\n",
        "            init_fn(worker_id)\n",
        "\n",
        "        watchdog = ManagerWatchdog()\n",
        "\n",
        "        while watchdog.is_alive():\n",
        "            try:\n",
        "                r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
        "            except queue.Empty:\n",
        "                continue\n",
        "\n",
        "            if r is None:\n",
        "                assert done_event.is_set()\n",
        "                return\n",
        "            elif done_event.is_set():\n",
        "                continue\n",
        "\n",
        "            idx, batch_indices = r\n",
        "            try:\n",
        "                idx_scale = 0\n",
        "                if len(scale) > 1 and dataset.train:\n",
        "                    idx_scale = random.randrange(0, len(scale))\n",
        "                    dataset.set_scale(idx_scale)\n",
        "\n",
        "                samples = collate_fn([dataset[i] for i in batch_indices])\n",
        "                samples.append(idx_scale)\n",
        "            except Exception:\n",
        "                data_queue.put((idx, ExceptionWrapper(sys.exc_info())))\n",
        "            else:\n",
        "                data_queue.put((idx, samples))\n",
        "                del samples\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "class _MSDataLoaderIter(_DataLoaderIter):\n",
        "\n",
        "    def __init__(self, loader):\n",
        "        self.dataset = loader.dataset\n",
        "        self.scale = loader.scale\n",
        "        self.collate_fn = loader.collate_fn\n",
        "        self.batch_sampler = loader.batch_sampler\n",
        "        self.num_workers = loader.num_workers\n",
        "        self.pin_memory = loader.pin_memory and torch.cuda.is_available()\n",
        "        self.timeout = loader.timeout\n",
        "\n",
        "        self.sample_iter = iter(self.batch_sampler)\n",
        "\n",
        "        base_seed = torch.LongTensor(1).random_().item()\n",
        "\n",
        "        if self.num_workers > 0:\n",
        "            self.worker_init_fn = loader.worker_init_fn\n",
        "            self.worker_queue_idx = 0\n",
        "            self.worker_result_queue = multiprocessing.Queue()\n",
        "            self.batches_outstanding = 0\n",
        "            self.worker_pids_set = False\n",
        "            self.shutdown = False\n",
        "            self.send_idx = 0\n",
        "            self.rcvd_idx = 0\n",
        "            self.reorder_dict = {}\n",
        "            self.done_event = multiprocessing.Event()\n",
        "\n",
        "            base_seed = torch.LongTensor(1).random_()[0]\n",
        "\n",
        "            self.index_queues = []\n",
        "            self.workers = []\n",
        "            for i in range(self.num_workers):\n",
        "                index_queue = multiprocessing.Queue()\n",
        "                index_queue.cancel_join_thread()\n",
        "                w = multiprocessing.Process(\n",
        "                    target=_ms_loop,\n",
        "                    args=(\n",
        "                        self.dataset,\n",
        "                        index_queue,\n",
        "                        self.worker_result_queue,\n",
        "                        self.done_event,\n",
        "                        self.collate_fn,\n",
        "                        self.scale,\n",
        "                        base_seed + i,\n",
        "                        self.worker_init_fn,\n",
        "                        i\n",
        "                    )\n",
        "                )\n",
        "                w.daemon = True\n",
        "                w.start()\n",
        "                self.index_queues.append(index_queue)\n",
        "                self.workers.append(w)\n",
        "\n",
        "            if self.pin_memory:\n",
        "                self.data_queue = queue.Queue()\n",
        "                pin_memory_thread = threading.Thread(\n",
        "                    target=_utils.pin_memory._pin_memory_loop,\n",
        "                    args=(\n",
        "                        self.worker_result_queue,\n",
        "                        self.data_queue,\n",
        "                        torch.cuda.current_device(),\n",
        "                        self.done_event\n",
        "                    )\n",
        "                )\n",
        "                pin_memory_thread.daemon = True\n",
        "                pin_memory_thread.start()\n",
        "                self.pin_memory_thread = pin_memory_thread\n",
        "            else:\n",
        "                self.data_queue = self.worker_result_queue\n",
        "\n",
        "            _utils.signal_handling._set_worker_pids(\n",
        "                id(self), tuple(w.pid for w in self.workers)\n",
        "            )\n",
        "            _utils.signal_handling._set_SIGCHLD_handler()\n",
        "            self.worker_pids_set = True\n",
        "\n",
        "            for _ in range(2 * self.num_workers):\n",
        "                self._put_indices()\n",
        "\n",
        "\n",
        "class MSDataLoader(DataLoader):\n",
        "\n",
        "    def __init__(self, cfg, *args, **kwargs):\n",
        "        super(MSDataLoader, self).__init__(\n",
        "            *args, **kwargs, num_workers=cfg.n_threads\n",
        "        )\n",
        "        self.scale = cfg.scale\n",
        "\n",
        "    def __iter__(self):\n",
        "        return _MSDataLoaderIter(self)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "qtxjdOdk82YC",
        "outputId": "c76cd47a-9c1a-4086-d060-661f1401bf2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-98c0ca0f82b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_DataLoaderIter' from 'torch.utils.data.dataloader' (/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description='IPT')\n",
        "\n",
        "parser.add_argument('--debug', action='store_true',\n",
        "                    help='Enables debug mode')\n",
        "parser.add_argument('--template', default='.',\n",
        "                    help='You can set various templates in option.py')\n",
        "\n",
        "# Hardware specifications\n",
        "parser.add_argument('--n_threads', type=int, default=6,\n",
        "                    help='number of threads for data loading')\n",
        "parser.add_argument('--cpu', action='store_true',\n",
        "                    help='use cpu only')\n",
        "parser.add_argument('--n_GPUs', type=int, default=1,\n",
        "                    help='number of GPUs')\n",
        "parser.add_argument('--seed', type=int, default=1,\n",
        "                    help='random seed')\n",
        "\n",
        "# Data specifications\n",
        "parser.add_argument('--dir_data', type=str, default='/cache/data/',\n",
        "                    help='dataset directory')\n",
        "parser.add_argument('--dir_demo', type=str, default='../test',\n",
        "                    help='demo image directory')\n",
        "parser.add_argument('--data_train', type=str, default='DIV2K',\n",
        "                    help='train dataset name')\n",
        "parser.add_argument('--data_test', type=str, default='DIV2K',\n",
        "                    help='test dataset name')\n",
        "parser.add_argument('--data_range', type=str, default='1-800/801-810',\n",
        "                    help='train/test data range')\n",
        "parser.add_argument('--ext', type=str, default='sep',\n",
        "                    help='dataset file extension')\n",
        "parser.add_argument('--scale', type=str, default='4',\n",
        "                    help='super resolution scale')\n",
        "parser.add_argument('--patch_size', type=int, default=48,\n",
        "                    help='output patch size')\n",
        "parser.add_argument('--rgb_range', type=int, default=255,\n",
        "                    help='maximum value of RGB')\n",
        "parser.add_argument('--n_colors', type=int, default=3,\n",
        "                    help='number of color channels to use')\n",
        "parser.add_argument('--no_augment', action='store_true',\n",
        "                    help='do not use data augmentation')\n",
        "\n",
        "# Model specifications\n",
        "parser.add_argument('--model', default='ipt',\n",
        "                    help='model name')\n",
        "parser.add_argument('--n_feats', type=int, default=64,\n",
        "                    help='number of feature maps')\n",
        "parser.add_argument('--shift_mean', default=True,\n",
        "                    help='subtract pixel mean from the input')\n",
        "parser.add_argument('--precision', type=str, default='single',\n",
        "                    choices=('single', 'half'),\n",
        "                    help='FP precision for test (single | half)')\n",
        "\n",
        "# Training specifications\n",
        "parser.add_argument('--reset', action='store_true',\n",
        "                    help='reset the training')\n",
        "parser.add_argument('--test_every', type=int, default=1000,\n",
        "                    help='do test per every N batches')\n",
        "parser.add_argument('--epochs', type=int, default=300,\n",
        "                    help='number of epochs to train')\n",
        "parser.add_argument('--batch_size', type=int, default=16,\n",
        "                    help='input batch size for training')\n",
        "parser.add_argument('--test_batch_size', type=int, default=1,\n",
        "                    help='input batch size for training')\n",
        "parser.add_argument('--crop_batch_size', type=int, default=64,\n",
        "                    help='input batch size for training')\n",
        "parser.add_argument('--split_batch', type=int, default=1,\n",
        "                    help='split the batch into smaller chunks')\n",
        "parser.add_argument('--self_ensemble', action='store_true',\n",
        "                    help='use self-ensemble method for test')\n",
        "parser.add_argument('--test_only', action='store_true',\n",
        "                    help='set this option to test the model')\n",
        "parser.add_argument('--gan_k', type=int, default=1,\n",
        "                    help='k value for adversarial loss')\n",
        "\n",
        "# Optimization specifications\n",
        "parser.add_argument('--lr', type=float, default=1e-4,\n",
        "                    help='learning rate')\n",
        "parser.add_argument('--decay', type=str, default='200',\n",
        "                    help='learning rate decay type')\n",
        "parser.add_argument('--gamma', type=float, default=0.5,\n",
        "                    help='learning rate decay factor for step decay')\n",
        "parser.add_argument('--optimizer', default='ADAM',\n",
        "                    choices=('SGD', 'ADAM', 'RMSprop'),\n",
        "                    help='optimizer to use (SGD | ADAM | RMSprop)')\n",
        "parser.add_argument('--momentum', type=float, default=0.9,\n",
        "                    help='SGD momentum')\n",
        "parser.add_argument('--betas', type=tuple, default=(0.9, 0.999),\n",
        "                    help='ADAM beta')\n",
        "parser.add_argument('--epsilon', type=float, default=1e-8,\n",
        "                    help='ADAM epsilon for numerical stability')\n",
        "parser.add_argument('--weight_decay', type=float, default=0,\n",
        "                    help='weight decay')\n",
        "parser.add_argument('--gclip', type=float, default=0,\n",
        "                    help='gradient clipping threshold (0 = no clipping)')\n",
        "\n",
        "# Loss specifications\n",
        "parser.add_argument('--loss', type=str, default='1*L1',\n",
        "                    help='loss function configuration')\n",
        "parser.add_argument('--skip_threshold', type=float, default='1e8',\n",
        "                    help='skipping batch that has large error')\n",
        "\n",
        "# Log specifications\n",
        "parser.add_argument('--save', type=str, default='/cache/results/ipt/',\n",
        "                    help='file name to save')\n",
        "parser.add_argument('--load', type=str, default='',\n",
        "                    help='file name to load')\n",
        "parser.add_argument('--resume', type=int, default=0,\n",
        "                    help='resume from specific checkpoint')\n",
        "parser.add_argument('--save_models', action='store_true',\n",
        "                    help='save all intermediate models')\n",
        "parser.add_argument('--print_every', type=int, default=100,\n",
        "                    help='how many batches to wait before logging training status')\n",
        "parser.add_argument('--save_results', action='store_true',\n",
        "                    help='save output results')\n",
        "parser.add_argument('--save_gt', action='store_true',\n",
        "                    help='save low-resolution and high-resolution images together')\n",
        "\n",
        "#cloud\n",
        "parser.add_argument('--moxfile', type=int, default=1)\n",
        "parser.add_argument('--data_url', type=str,help='path to dataset')\n",
        "parser.add_argument('--train_url', type=str, help='train_dir')\n",
        "parser.add_argument('--pretrain', type=str, default='')\n",
        "parser.add_argument('--load_query', type=int, default=0)\n",
        "\n",
        "#transformer\n",
        "parser.add_argument('--patch_dim', type=int, default=3)\n",
        "parser.add_argument('--num_heads', type=int, default=12)\n",
        "parser.add_argument('--num_layers', type=int, default=12)\n",
        "parser.add_argument('--dropout_rate', type=float, default=0)\n",
        "parser.add_argument('--no_norm', action='store_true')\n",
        "parser.add_argument('--freeze_norm', action='store_true')\n",
        "parser.add_argument('--post_norm', action='store_true')\n",
        "parser.add_argument('--no_mlp', action='store_true')\n",
        "parser.add_argument('--pos_every', action='store_true')\n",
        "parser.add_argument('--no_pos', action='store_true')\n",
        "parser.add_argument('--num_queries', type=int, default=1)\n",
        "\n",
        "#denoise\n",
        "parser.add_argument('--denoise', action='store_true')\n",
        "parser.add_argument('--sigma', type=float, default=30)\n",
        "\n",
        "#derain\n",
        "parser.add_argument('--derain', action='store_true')\n",
        "parser.add_argument('--derain_test', type=int, default=1)\n",
        "\n",
        "#deblur\n",
        "parser.add_argument('--deblur', action='store_true')\n",
        "parser.add_argument('--deblur_test', type=int, default=1)\n",
        "\n",
        "\n",
        "args, unparsed = parser.parse_known_args()\n",
        "\n",
        "args.scale = list(map(lambda x: int(x), args.scale.split('+')))\n",
        "args.data_train = args.data_train.split('+')\n",
        "args.data_test = args.data_test.split('+')\n",
        "\n",
        "    \n",
        "if args.epochs == 0:\n",
        "    args.epochs = 1e8\n",
        "\n",
        "for arg in vars(args):\n",
        "    if vars(args)[arg] == 'True':\n",
        "        vars(args)[arg] = True\n",
        "    elif vars(args)[arg] == 'False':\n",
        "        vars(args)[arg] = False\n"
      ],
      "metadata": {
        "id": "pXCpiGd_AIQa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "\n",
        "from option import args\n",
        "\n",
        "import torch\n",
        "import utility\n",
        "import data\n",
        "import loss\n",
        "from trainer import Trainer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "os.system('pip install einops')\n",
        "import model\n",
        "torch.manual_seed(args.seed)\n",
        "checkpoint = utility.checkpoint(args)\n",
        "\n",
        "def main():\n",
        "    global model\n",
        "    if checkpoint.ok:\n",
        "        loader = data.Data(args)\n",
        "        _model = model.Model(args, checkpoint)\n",
        "        if args.pretrain != \"\":\n",
        "            if 's3' in args.pretrain:\n",
        "                import moxing as mox\n",
        "                mox.file.copy_parallel(args.pretrain,\"/cache/models/ipt.pt\")\n",
        "                args.pretrain = \"/cache/models/ipt.pt\"\n",
        "            state_dict = torch.load(args.pretrain)\n",
        "            _model.model.load_state_dict(state_dict,strict = False)\n",
        "        _loss = loss.Loss(args, checkpoint) if not args.test_only else None\n",
        "        t = Trainer(args, loader, _model, _loss, checkpoint)\n",
        "        t.test()\n",
        "        checkpoint.done()\n",
        "            \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Ws2RaNSE_f-C",
        "outputId": "22de4f11-07ec-42c0-952e-cfcc1d78be21"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-82b848c5efc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#            Huawei Technologies Co., Ltd. <foss@huawei.com>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0moption\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'option'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YYdyK27CD5u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import datetime\n",
        "from multiprocessing import Process\n",
        "from multiprocessing import Queue\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lrs\n",
        "\n",
        "class timer():\n",
        "    def __init__(self):\n",
        "        self.acc = 0\n",
        "        self.tic()\n",
        "\n",
        "    def tic(self):\n",
        "        self.t0 = time.time()\n",
        "\n",
        "    def toc(self, restart=False):\n",
        "        diff = time.time() - self.t0\n",
        "        if restart: self.t0 = time.time()\n",
        "        return diff\n",
        "\n",
        "    def hold(self):\n",
        "        self.acc += self.toc()\n",
        "\n",
        "    def release(self):\n",
        "        ret = self.acc\n",
        "        self.acc = 0\n",
        "\n",
        "        return ret\n",
        "\n",
        "    def reset(self):\n",
        "        self.acc = 0\n",
        "\n",
        "class checkpoint():\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.ok = True\n",
        "        self.log = torch.Tensor()\n",
        "        now = datetime.datetime.now().strftime('%Y-%m-%d-%H:%M:%S')\n",
        "\n",
        "        if not args.load:\n",
        "            if not args.save:\n",
        "                args.save = now\n",
        "            self.dir = os.path.join('..', 'experiment', args.save)\n",
        "        else:\n",
        "            self.dir = os.path.join('..', 'experiment', args.load)\n",
        "            if os.path.exists(self.dir):\n",
        "                self.log = torch.load(self.get_path('psnr_log.pt'))\n",
        "                print('Continue from epoch {}...'.format(len(self.log)))\n",
        "            else:\n",
        "                args.load = ''\n",
        "\n",
        "        if args.reset:\n",
        "            os.system('rm -rf ' + self.dir)\n",
        "            args.load = ''\n",
        "\n",
        "        os.makedirs(self.dir, exist_ok=True)\n",
        "        os.makedirs(self.get_path('model'), exist_ok=True)\n",
        "        for d in args.data_test:\n",
        "            os.makedirs(self.get_path('results-{}'.format(d)), exist_ok=True)\n",
        "\n",
        "        open_type = 'a' if os.path.exists(self.get_path('log.txt'))else 'w'\n",
        "        self.log_file = open(self.get_path('log.txt'), open_type)\n",
        "        with open(self.get_path('config.txt'), open_type) as f:\n",
        "            f.write(now + '\\n\\n')\n",
        "            for arg in vars(args):\n",
        "                f.write('{}: {}\\n'.format(arg, getattr(args, arg)))\n",
        "            f.write('\\n')\n",
        "\n",
        "        self.n_processes = 8\n",
        "\n",
        "    def get_path(self, *subdir):\n",
        "        return os.path.join(self.dir, *subdir)\n",
        "\n",
        "    def save(self, trainer, epoch, is_best=False):\n",
        "        trainer.model.save(self.get_path('model'), epoch, is_best=is_best)\n",
        "        trainer.loss.save(self.dir)\n",
        "        trainer.loss.plot_loss(self.dir, epoch)\n",
        "\n",
        "        self.plot_psnr(epoch)\n",
        "        trainer.optimizer.save(self.dir)\n",
        "        torch.save(self.log, self.get_path('psnr_log.pt'))\n",
        "\n",
        "    def add_log(self, log):\n",
        "        self.log = torch.cat([self.log, log])\n",
        "\n",
        "    def write_log(self, log, refresh=False):\n",
        "        print(log)\n",
        "        self.log_file.write(log + '\\n')\n",
        "        if refresh:\n",
        "            self.log_file.close()\n",
        "            self.log_file = open(self.get_path('log.txt'), 'a')\n",
        "\n",
        "    def done(self):\n",
        "        self.log_file.close()\n",
        "\n",
        "    def plot_psnr(self, epoch):\n",
        "        axis = np.linspace(1, epoch, epoch)\n",
        "        for idx_data, d in enumerate(self.args.data_test):\n",
        "            label = 'SR on {}'.format(d)\n",
        "            fig = plt.figure()\n",
        "            plt.title(label)\n",
        "            for idx_scale, scale in enumerate(self.args.scale):\n",
        "                plt.plot(\n",
        "                    axis,\n",
        "                    self.log[:, idx_data, idx_scale].numpy(),\n",
        "                    label='Scale {}'.format(scale)\n",
        "                )\n",
        "            plt.legend()\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel('PSNR')\n",
        "            plt.grid(True)\n",
        "            plt.savefig(self.get_path('test_{}.pdf'.format(d)))\n",
        "            plt.close(fig)\n",
        "\n",
        "    def begin_background(self):\n",
        "        self.queue = Queue()\n",
        "\n",
        "        def bg_target(queue):\n",
        "            while True:\n",
        "                if not queue.empty():\n",
        "                    filename, tensor = queue.get()\n",
        "                    if filename is None: break\n",
        "                    imageio.imwrite(filename, tensor.numpy())\n",
        "        \n",
        "        self.process = [\n",
        "            Process(target=bg_target, args=(self.queue,)) \\\n",
        "            for _ in range(self.n_processes)\n",
        "        ]\n",
        "        \n",
        "        for p in self.process: p.start()\n",
        "\n",
        "    def end_background(self):\n",
        "        for _ in range(self.n_processes): self.queue.put((None, None))\n",
        "        while not self.queue.empty(): time.sleep(1)\n",
        "        for p in self.process: p.join()\n",
        "\n",
        "    def save_results(self, dataset, filename, save_list, scale):\n",
        "        if self.args.save_results:\n",
        "            filename = self.get_path(\n",
        "                'results-{}'.format(dataset.dataset.name),\n",
        "                '{}_x{}_'.format(filename, scale)\n",
        "            )\n",
        "\n",
        "            postfix = ('SR', 'LR', 'HR')\n",
        "            for v, p in zip(save_list, postfix):\n",
        "                normalized = v[0].mul(255 / self.args.rgb_range)\n",
        "                tensor_cpu = normalized.byte().permute(1, 2, 0).cpu()\n",
        "                self.queue.put(('{}{}.png'.format(filename, p), tensor_cpu))\n",
        "\n",
        "def quantize(img, rgb_range):\n",
        "    pixel_range = 255 / rgb_range\n",
        "    return img.mul(pixel_range).clamp(0, 255).round().div(pixel_range)\n",
        "\n",
        "def calc_psnr(sr, hr, scale, rgb_range, cal_type='y'):\n",
        "    if hr.nelement() == 1: return 0\n",
        "\n",
        "    diff = (sr - hr) / rgb_range\n",
        "    \n",
        "    if cal_type=='y':\n",
        "        gray_coeffs = [65.738, 129.057, 25.064]\n",
        "        convert = diff.new_tensor(gray_coeffs).view(1, 3, 1, 1) / 256\n",
        "        diff = diff.mul(convert).sum(dim=1)\n",
        "    \n",
        "    if scale == 1:\n",
        "        valid = diff\n",
        "    else:\n",
        "        valid = diff[..., scale:-scale, scale:-scale]\n",
        "    mse = valid.pow(2).mean()\n",
        "\n",
        "    return -10 * math.log10(mse)\n",
        "\n",
        "def make_optimizer(args, target):\n",
        "    '''\n",
        "        make optimizer and scheduler together\n",
        "    '''\n",
        "    # optimizer\n",
        "    trainable = filter(lambda x: x.requires_grad, target.parameters())\n",
        "    kwargs_optimizer = {'lr': args.lr, 'weight_decay': args.weight_decay}\n",
        "\n",
        "    if args.optimizer == 'SGD':\n",
        "        optimizer_class = optim.SGD\n",
        "        kwargs_optimizer['momentum'] = args.momentum\n",
        "    elif args.optimizer == 'ADAM':\n",
        "        optimizer_class = optim.Adam\n",
        "        kwargs_optimizer['betas'] = args.betas\n",
        "        kwargs_optimizer['eps'] = args.epsilon\n",
        "    elif args.optimizer == 'RMSprop':\n",
        "        optimizer_class = optim.RMSprop\n",
        "        kwargs_optimizer['eps'] = args.epsilon\n",
        "\n",
        "    # scheduler\n",
        "    milestones = list(map(lambda x: int(x), args.decay.split('-')))\n",
        "    kwargs_scheduler = {'milestones': milestones, 'gamma': args.gamma}\n",
        "    scheduler_class = lrs.MultiStepLR\n",
        "\n",
        "    class CustomOptimizer(optimizer_class):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            super(CustomOptimizer, self).__init__(*args, **kwargs)\n",
        "\n",
        "        def _register_scheduler(self, scheduler_class, **kwargs):\n",
        "            self.scheduler = scheduler_class(self, **kwargs)\n",
        "\n",
        "        def save(self, save_dir):\n",
        "            torch.save(self.state_dict(), self.get_dir(save_dir))\n",
        "\n",
        "        def load(self, load_dir, epoch=1):\n",
        "            self.load_state_dict(torch.load(self.get_dir(load_dir)))\n",
        "            if epoch > 1:\n",
        "                for _ in range(epoch): self.scheduler.step()\n",
        "\n",
        "        def get_dir(self, dir_path):\n",
        "            return os.path.join(dir_path, 'optimizer.pt')\n",
        "\n",
        "        def schedule(self):\n",
        "            self.scheduler.step()\n",
        "\n",
        "        def get_lr(self):\n",
        "            return self.scheduler.get_lr()[0]\n",
        "\n",
        "        def get_last_epoch(self):\n",
        "            return self.scheduler.last_epoch\n",
        "    \n",
        "    optimizer = CustomOptimizer(trainable, **kwargs_optimizer)\n",
        "    optimizer._register_scheduler(scheduler_class, **kwargs_scheduler)\n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "AfKPaSo5EwHz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "\n",
        "import utility\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, args, loader, my_model, my_loss, ckp):\n",
        "        self.args = args\n",
        "        self.scale = args.scale\n",
        "\n",
        "        self.ckp = ckp\n",
        "        self.loader_train = loader.loader_train\n",
        "        self.loader_test = loader.loader_test\n",
        "        self.model = my_model\n",
        "        self.loss = my_loss\n",
        "        self.optimizer = utility.make_optimizer(args, self.model)\n",
        "        if self.args.load != '':\n",
        "            self.optimizer.load(ckp.dir, epoch=len(ckp.log))\n",
        "\n",
        "        self.error_last = 1e8\n",
        "\n",
        "    def test(self):\n",
        "        torch.set_grad_enabled(False)\n",
        "\n",
        "        epoch = self.optimizer.get_last_epoch()\n",
        "        self.ckp.write_log('\\nEvaluation:')\n",
        "        self.ckp.add_log(\n",
        "            torch.zeros(1, len(self.loader_test), len(self.scale))\n",
        "        )\n",
        "        self.model.eval()\n",
        "        timer_test = utility.timer()\n",
        "        if self.args.save_results: self.ckp.begin_background()\n",
        "        for idx_data, d in enumerate(self.loader_test):\n",
        "            i = 0\n",
        "            for idx_scale, scale in enumerate(self.scale):\n",
        "                d.dataset.set_scale(idx_scale)\n",
        "                if self.args.derain:\n",
        "                    for norain, rain, filename in tqdm(d, ncols=80):\n",
        "                        norain,rain = self.prepare(norain, rain)\n",
        "                        sr = self.model(rain, idx_scale)\n",
        "                        sr = utility.quantize(sr, self.args.rgb_range)\n",
        "                        \n",
        "                        save_list = [sr]\n",
        "                        self.ckp.log[-1, idx_data, idx_scale] += utility.calc_psnr(\n",
        "                            sr, norain, scale, self.args.rgb_range\n",
        "                        ) \n",
        "                        if self.args.save_results:\n",
        "                            self.ckp.save_results(d, filename[0], save_list, 1)\n",
        "                    self.ckp.log[-1, idx_data, idx_scale] /= len(d)\n",
        "                    best = self.ckp.log.max(0)\n",
        "                    self.ckp.write_log(\n",
        "                        '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
        "                            d.dataset.name,\n",
        "                            scale,\n",
        "                            self.ckp.log[-1, idx_data, idx_scale],\n",
        "                            best[0][idx_data, idx_scale],\n",
        "                            best[1][idx_data, idx_scale] + 1\n",
        "                        )\n",
        "                    )\n",
        "                    isderain = 0\n",
        "                elif self.args.denoise:\n",
        "                    for hr, _,filename in tqdm(d, ncols=80):\n",
        "                        hr = self.prepare(hr)[0]\n",
        "                        noisy_level = self.args.sigma\n",
        "                        noise = torch.randn(hr.size()).mul_(noisy_level).cuda()\n",
        "                        nois_hr = (noise+hr).clamp(0,255)\n",
        "                        sr = self.model(nois_hr, idx_scale)\n",
        "                        sr = utility.quantize(sr, self.args.rgb_range)\n",
        "\n",
        "                        save_list = [sr, nois_hr, hr]\n",
        "                        self.ckp.log[-1, idx_data, idx_scale] += utility.calc_psnr(\n",
        "                            sr, hr, scale, self.args.rgb_range\n",
        "                        )\n",
        "                        if self.args.save_results:\n",
        "                            self.ckp.save_results(d, filename[0], save_list, 50)\n",
        "\n",
        "                    self.ckp.log[-1, idx_data, idx_scale] /= len(d)\n",
        "                    best = self.ckp.log.max(0)\n",
        "                    self.ckp.write_log(\n",
        "                        '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
        "                            d.dataset.name,\n",
        "                            scale,\n",
        "                            self.ckp.log[-1, idx_data, idx_scale],\n",
        "                            best[0][idx_data, idx_scale],\n",
        "                            best[1][idx_data, idx_scale] + 1\n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    for lr, hr, filename in tqdm(d, ncols=80):\n",
        "                        lr, hr = self.prepare(lr, hr)\n",
        "                        sr = self.model(lr, idx_scale)\n",
        "                        sr = utility.quantize(sr, self.args.rgb_range)\n",
        "\n",
        "                        save_list = [sr]\n",
        "                        self.ckp.log[-1, idx_data, idx_scale] += utility.calc_psnr(\n",
        "                            sr, hr, scale, self.args.rgb_range\n",
        "                        )\n",
        "                        #import pdb\n",
        "                        #pdb.set_trace()\n",
        "                        if self.args.save_gt:\n",
        "                            save_list.extend([lr, hr])\n",
        "\n",
        "                        if self.args.save_results:\n",
        "                            self.ckp.save_results(d, filename[0], save_list, scale)\n",
        "                        i = i+1\n",
        "                    self.ckp.log[-1, idx_data, idx_scale] /= len(d)\n",
        "                    best = self.ckp.log.max(0)\n",
        "                    self.ckp.write_log(\n",
        "                        '[{} x{}]\\tPSNR: {:.3f} (Best: {:.3f} @epoch {})'.format(\n",
        "                            d.dataset.name,\n",
        "                            scale,\n",
        "                            self.ckp.log[-1, idx_data, idx_scale],\n",
        "                            best[0][idx_data, idx_scale],\n",
        "                            best[1][idx_data, idx_scale] + 1\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "        self.ckp.write_log('Forward: {:.2f}s\\n'.format(timer_test.toc()))\n",
        "        self.ckp.write_log('Saving...')\n",
        "\n",
        "        if self.args.save_results:\n",
        "            self.ckp.end_background()\n",
        "\n",
        "        self.ckp.write_log(\n",
        "            'Total: {:.2f}s\\n'.format(timer_test.toc()), refresh=True\n",
        "        )\n",
        "\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "    def prepare(self, *args):\n",
        "        device = torch.device('cpu' if self.args.cpu else 'cuda')\n",
        "        def _prepare(tensor):\n",
        "            if self.args.precision == 'half': tensor = tensor.half()\n",
        "            return tensor.to(device)\n",
        "\n",
        "        return [_prepare(a) for a in args]\n",
        "\n",
        "    def terminate(self):\n",
        "        if self.args.test_only:\n",
        "            self.test()\n",
        "            return True\n",
        "        else:\n",
        "            epoch = self.optimizer.get_last_epoch() + 1\n",
        "            return epoch >= self.args.epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Il09VSG6D4d0",
        "outputId": "69d3485e-29ae-4fa6-99db-0c48f12f48fc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ffb67221c771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#            Huawei Technologies Co., Ltd. <foss@huawei.com>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utility'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2021.05.07-Changed for IPT\n",
        "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
        "\n",
        "import os\n",
        "from importlib import import_module\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Loss(nn.modules.loss._Loss):\n",
        "    def __init__(self, args, ckp):\n",
        "        super(Loss, self).__init__()\n",
        "        print('Preparing loss function:')\n",
        "\n",
        "        self.n_GPUs = args.n_GPUs\n",
        "        self.loss = []\n",
        "        self.loss_module = nn.ModuleList()\n",
        "        for loss in args.loss.split('+'):\n",
        "            weight, loss_type = loss.split('*')\n",
        "            if loss_type == 'MSE':\n",
        "                loss_function = nn.MSELoss()\n",
        "            elif loss_type == 'L1':\n",
        "                loss_function = nn.L1Loss()\n",
        "\n",
        "            self.loss.append({\n",
        "                'type': loss_type,\n",
        "                'weight': float(weight),\n",
        "                'function': loss_function}\n",
        "            )\n",
        "\n",
        "        if len(self.loss) > 1:\n",
        "            self.loss.append({'type': 'Total', 'weight': 0, 'function': None})\n",
        "\n",
        "        for l in self.loss:\n",
        "            if l['function'] is not None:\n",
        "                print('{:.3f} * {}'.format(l['weight'], l['type']))\n",
        "                self.loss_module.append(l['function'])\n",
        "\n",
        "        self.log = torch.Tensor()\n",
        "\n",
        "        device = torch.device('cpu' if args.cpu else 'cuda')\n",
        "        self.loss_module.to(device)\n",
        "        if args.precision == 'half': self.loss_module.half()\n",
        "        if not args.cpu and args.n_GPUs > 1:\n",
        "            self.loss_module = nn.DataParallel(\n",
        "                self.loss_module, range(args.n_GPUs)\n",
        "            )\n",
        "\n",
        "        if args.load != '': self.load(ckp.dir, cpu=args.cpu)\n",
        "\n",
        "    def forward(self, sr, hr):\n",
        "        losses = []\n",
        "        for i, l in enumerate(self.loss):\n",
        "            if l['function'] is not None:\n",
        "                loss = l['function'](sr, hr)\n",
        "                effective_loss = l['weight'] * loss\n",
        "                losses.append(effective_loss)\n",
        "                self.log[-1, i] += effective_loss.item()\n",
        "            elif l['type'] == 'DIS':\n",
        "                self.log[-1, i] += self.loss[i - 1]['function'].loss\n",
        "\n",
        "        loss_sum = sum(losses)\n",
        "        if len(self.loss) > 1:\n",
        "            self.log[-1, -1] += loss_sum.item()\n",
        "\n",
        "        return loss_sum\n",
        "\n",
        "    def step(self):\n",
        "        for l in self.get_loss_module():\n",
        "            if hasattr(l, 'scheduler'):\n",
        "                l.scheduler.step()\n",
        "\n",
        "    def start_log(self):\n",
        "        self.log = torch.cat((self.log, torch.zeros(1, len(self.loss))))\n",
        "\n",
        "    def end_log(self, n_batches):\n",
        "        self.log[-1].div_(n_batches)\n",
        "\n",
        "    def display_loss(self, batch):\n",
        "        n_samples = batch + 1\n",
        "        log = []\n",
        "        for l, c in zip(self.loss, self.log[-1]):\n",
        "            log.append('[{}: {:.4f}]'.format(l['type'], c / n_samples))\n",
        "\n",
        "        return ''.join(log)\n",
        "\n",
        "    def plot_loss(self, apath, epoch):\n",
        "        axis = np.linspace(1, epoch, epoch)\n",
        "        for i, l in enumerate(self.loss):\n",
        "            label = '{} Loss'.format(l['type'])\n",
        "            fig = plt.figure()\n",
        "            plt.title(label)\n",
        "            plt.plot(axis, self.log[:, i].numpy(), label=label)\n",
        "            plt.legend()\n",
        "            plt.xlabel('Epochs')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.grid(True)\n",
        "            plt.savefig(os.path.join(apath, 'loss_{}.pdf'.format(l['type'])))\n",
        "            plt.close(fig)\n",
        "\n",
        "    def get_loss_module(self):\n",
        "        if self.n_GPUs == 1:\n",
        "            return self.loss_module\n",
        "        else:\n",
        "            return self.loss_module.module\n",
        "\n",
        "    def save(self, apath):\n",
        "        torch.save(self.state_dict(), os.path.join(apath, 'loss.pt'))\n",
        "        torch.save(self.log, os.path.join(apath, 'loss_log.pt'))\n",
        "\n",
        "    def load(self, apath, cpu=False):\n",
        "        if cpu:\n",
        "            kwargs = {'map_location': lambda storage, loc: storage}\n",
        "        else:\n",
        "            kwargs = {}\n",
        "\n",
        "        self.load_state_dict(torch.load(\n",
        "            os.path.join(apath, 'loss.pt'),\n",
        "            **kwargs\n",
        "        ))\n",
        "        self.log = torch.load(os.path.join(apath, 'loss_log.pt'))\n",
        "        for l in self.get_loss_module():\n",
        "            if hasattr(l, 'scheduler'):\n",
        "                for _ in range(len(self.log)): l.scheduler.step()\n"
      ],
      "metadata": {
        "id": "kMZWWztXFQz6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zqnoouc_Fqt8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}